/**
 * CopyInventoryFromNotecard Packet
 *
 * This file is used to help our packet serialization and deserialization
 * process, and to create new packets on the fly.
 *
 * ⚠️ Do not edit this file manually, it is generated by the `codegen` script!
 *
 * @see {@link http://wiki.secondlife.com/wiki/Message_Layout}
 */

import type { DeepRequired } from "ts-essentials"
import * as PacketEncoder from "~/codec/lludp/packet-encoder"
import * as Primitives from "~/codec/primitives"
import type * as Types from "~/model/types"

export interface CopyInventoryFromNotecardData {
	agentData?: {
		agentId?: Types.UUID
		sessionId?: Types.UUID
	}
	notecardData: {
		notecardItemId: Types.UUID
		objectId: Types.UUID
	}
	inventoryData: {
		itemId: Types.UUID
		folderId: Types.UUID
	}[]
}

export const id = 265
export const name = "CopyInventoryFromNotecard"
export const frequency = 2
export const compression = true

const HEADER_SIZE = PacketEncoder.FREQUENCY_OFFSETS[frequency]!

// base byte size for one "agentData" entry (fixed-length parameters only)
const AGENT_DATA_BASE_SIZE =
	Primitives.UUID.size() + // agentId
	Primitives.UUID.size() // sessionId

// base byte size for one "notecardData" entry (fixed-length parameters only)
const NOTECARD_DATA_BASE_SIZE =
	Primitives.UUID.size() + // notecardItemId
	Primitives.UUID.size() // objectId

// base byte size for one "inventoryData" entry (fixed-length parameters only)
const INVENTORY_DATA_BASE_SIZE =
	Primitives.UUID.size() + // itemId
	Primitives.UUID.size() // folderId

// size contributed by the packet header and all FIXED-LENGTH fields
const BASE_SIZE =
	// Header
	HEADER_SIZE + AGENT_DATA_BASE_SIZE + NOTECARD_DATA_BASE_SIZE

export function encode(sequence: number, reliable: boolean, data: DeepRequired<CopyInventoryFromNotecardData>) {
	let size = BASE_SIZE

	// add 1 byte for the block count
	size += Primitives.U8.size()

	size += INVENTORY_DATA_BASE_SIZE * (data.inventoryData?.length ?? 0)

	const buffer = Buffer.allocUnsafe(size)

	PacketEncoder.encodeHeader(buffer, id, frequency, sequence, reliable)

	let offset = HEADER_SIZE

	// AgentData
	offset = Primitives.UUID.encode(data.agentData.agentId, buffer, offset)
	offset = Primitives.UUID.encode(data.agentData.sessionId, buffer, offset)

	// NotecardData
	offset = Primitives.UUID.encode(data.notecardData.notecardItemId, buffer, offset)
	offset = Primitives.UUID.encode(data.notecardData.objectId, buffer, offset)

	// InventoryData
	offset = Primitives.U8.encode(data.inventoryData?.length ?? 0, buffer, offset)

	for (const item of data.inventoryData ?? []) {
		offset = Primitives.UUID.encode(item.itemId, buffer, offset)
		offset = Primitives.UUID.encode(item.folderId, buffer, offset)
	}

	return buffer
}

export function decode(buffer: Buffer): CopyInventoryFromNotecardData {
	const state = { offset: HEADER_SIZE }

	return {
		agentData: {
			agentId: Primitives.UUID.decode(buffer, state),
			sessionId: Primitives.UUID.decode(buffer, state),
		},
		notecardData: {
			notecardItemId: Primitives.UUID.decode(buffer, state),
			objectId: Primitives.UUID.decode(buffer, state),
		},
		inventoryData: (() => {
			const items: CopyInventoryFromNotecardData["inventoryData"] = []
			const size = Primitives.U8.decode(buffer, state)

			for (let i = 0; i < size; i++) {
				items.push({
					itemId: Primitives.UUID.decode(buffer, state),
					folderId: Primitives.UUID.decode(buffer, state),
				})
			}

			return items
		})(),
	}
}
