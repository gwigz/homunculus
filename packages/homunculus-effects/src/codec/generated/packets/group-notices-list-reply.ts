/**
 * GroupNoticesListReply Packet
 *
 * This file is used to help our packet serialization and deserialization
 * process, and to create new packets on the fly.
 *
 * ⚠️ Do not edit this file manually, it is generated by the `codegen` script!
 *
 * @see {@link http://wiki.secondlife.com/wiki/Message_Layout}
 */

import type { DeepRequired } from "ts-essentials"
import * as PacketEncoder from "~/codec/lludp/packet-encoder"
import * as Primitives from "~/codec/primitives"
import type * as Types from "~/model/types"

export interface GroupNoticesListReplyData {
	agentData: {
		agentId?: Types.UUID
		groupId: Types.UUID
	}
	data: {
		noticeId: Types.UUID
		timestamp: number
		fromName: Buffer
		subject: Buffer
		hasAttachment: boolean
		assetType: number
	}[]
}

export const id = 59
export const name = "GroupNoticesListReply"
export const frequency = 2

const HEADER_SIZE = PacketEncoder.FREQUENCY_OFFSETS[frequency]!

// base byte size for one "agentData" entry (fixed-length parameters only)
const AGENT_DATA_BASE_SIZE =
	Primitives.UUID.size() + // agentId
	Primitives.UUID.size() // groupId

// base byte size for one "data" entry (fixed-length parameters only)
const DATA_BASE_SIZE =
	Primitives.UUID.size() + // noticeId
	Primitives.U32.size() + // timestamp
	Primitives.Boolean.size() + // hasAttachment
	Primitives.U8.size() // assetType

// size contributed by the packet header and all FIXED-LENGTH fields
const BASE_SIZE =
	// Header
	HEADER_SIZE + AGENT_DATA_BASE_SIZE

export function encode(sequence: number, reliable: boolean, data: DeepRequired<GroupNoticesListReplyData>) {
	let size = BASE_SIZE

	// add 1 byte for the block count
	size += Primitives.U8.size()

	size += DATA_BASE_SIZE * (data.data?.length ?? 0)

	for (const item of data.data ?? []) {
		size += Primitives.Variable2.size(item.fromName)
		size += Primitives.Variable2.size(item.subject)
	}

	const buffer = Buffer.allocUnsafe(size)

	PacketEncoder.encodeHeader(buffer, id, frequency, sequence, reliable)

	let offset = HEADER_SIZE

	// AgentData
	offset = Primitives.UUID.encode(data.agentData.agentId, buffer, offset)
	offset = Primitives.UUID.encode(data.agentData.groupId, buffer, offset)

	// Data
	offset = Primitives.U8.encode(data.data?.length ?? 0, buffer, offset)

	for (const item of data.data ?? []) {
		offset = Primitives.UUID.encode(item.noticeId, buffer, offset)
		offset = Primitives.U32.encode(item.timestamp, buffer, offset)
		offset = Primitives.Variable2.encode(item.fromName, buffer, offset)
		offset = Primitives.Variable2.encode(item.subject, buffer, offset)
		offset = Primitives.Boolean.encode(item.hasAttachment, buffer, offset)
		offset = Primitives.U8.encode(item.assetType, buffer, offset)
	}

	return buffer
}

export function decode(buffer: Buffer): GroupNoticesListReplyData {
	const state = { offset: HEADER_SIZE }

	return {
		agentData: {
			agentId: Primitives.UUID.decode(buffer, state),
			groupId: Primitives.UUID.decode(buffer, state),
		},
		data: (() => {
			const items: GroupNoticesListReplyData["data"] = []
			const size = Primitives.U8.decode(buffer, state)

			for (let i = 0; i < size; i++) {
				items.push({
					noticeId: Primitives.UUID.decode(buffer, state),
					timestamp: Primitives.U32.decode(buffer, state),
					fromName: Primitives.Variable2.decode(buffer, state),
					subject: Primitives.Variable2.decode(buffer, state),
					hasAttachment: Primitives.Boolean.decode(buffer, state),
					assetType: Primitives.U8.decode(buffer, state),
				})
			}

			return items
		})(),
	}
}
